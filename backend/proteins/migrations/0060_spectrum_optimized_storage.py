# Generated by Django 5.2.8 on 2025-11-26

from __future__ import annotations

import struct

import numpy as np
from django.db import connection, migrations, models


def encode_y_values(y_list: list[float]) -> bytes:
    """Encode list of floats to float32 binary data."""
    return struct.pack(f"<{len(y_list)}f", *y_list)


def column_exists(table: str, column: str) -> bool:
    """Check if a column exists in the database."""
    with connection.cursor() as cursor:
        cursor.execute(
            """
            SELECT COUNT(*) FROM information_schema.columns
            WHERE table_name = %s AND column_name = %s
            """,
            [table, column],
        )
        row = cursor.fetchone()
        return row is not None and row[0] > 0


def compute_peak_wave(min_wave: int, y_values: bytes) -> int | None:
    """Compute peak wavelength from spectrum data."""
    if not y_values:
        return None

    y = np.frombuffer(y_values, dtype="<f4").tolist()
    x = list(range(min_wave, min_wave + len(y)))

    try:
        if min_wave < 300:
            # Find max Y where X > 300
            valid_y = [i for n, i in enumerate(y) if x[n] > 300]
            if not valid_y:
                return None
            max_y = max(valid_y)
            return x[y.index(max_y)]
        else:
            try:
                # First look for value 1 (to avoid false 2P peaks)
                return x[y.index(1)]
            except ValueError:
                return x[y.index(max(y))]
    except ValueError:
        return None


def migrate_spectrum_data(apps, schema_editor):
    """Convert legacy data format to optimized storage format."""
    Spectrum = apps.get_model("proteins", "Spectrum")
    FluorState = apps.get_model("proteins", "FluorState")

    # Check if migration already happened (y_values populated)
    if Spectrum.objects.filter(y_values__isnull=False).exists():
        print("\n  Data already migrated, skipping...")
        return

    batch_size = 500
    total = Spectrum.objects.count()
    print(f"\nMigrating {total} spectra to optimized storage format...")

    for offset in range(0, total, batch_size):
        spectra = list(
            Spectrum.objects.select_related("owner_fluor")
            .order_by("id")[offset : offset + batch_size]
        )

        for spectrum in spectra:
            if not spectrum.data:
                print(f"  Warning: Spectrum {spectrum.id} has no data, skipping")
                continue

            # Extract wavelengths and y values from legacy format
            wavelengths = [int(point[0]) for point in spectrum.data]
            y_values = [point[1] for point in spectrum.data]

            # Set min/max wave
            spectrum.min_wave = min(wavelengths)
            spectrum.max_wave = max(wavelengths)

            # Encode y values as float32 binary
            spectrum.y_values = encode_y_values(y_values)

            # Compute peak_wave
            spectrum.peak_wave = compute_peak_wave(spectrum.min_wave, spectrum.y_values)

            # Populate scale_factor from owner based on subtype
            if spectrum.owner_fluor_id:
                try:
                    fluor = FluorState.objects.get(pk=spectrum.owner_fluor_id)
                    if spectrum.subtype in ("ex", "ab"):
                        spectrum.scale_factor = fluor.ext_coeff
                    elif spectrum.subtype == "em":
                        spectrum.scale_factor = fluor.qy
                    elif spectrum.subtype == "2p":
                        spectrum.scale_factor = fluor.twop_peak_gm
                except FluorState.DoesNotExist:
                    pass
            else:
                # For filters, cameras, lights - scale_factor is 1.0
                spectrum.scale_factor = 1.0

            spectrum.save(
                update_fields=[
                    "min_wave",
                    "max_wave",
                    "y_values",
                    "peak_wave",
                    "scale_factor",
                ]
            )

        print(f"  Processed {min(offset + batch_size, total)}/{total} spectra")


class ConditionalAddField(migrations.AddField):
    """AddField that skips if column already exists."""

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        model = to_state.apps.get_model(app_label, self.model_name)
        if not column_exists(model._meta.db_table, self.field.db_column or self.name):
            super().database_forwards(app_label, schema_editor, from_state, to_state)


class ConditionalRemoveField(migrations.RemoveField):
    """RemoveField that skips if column doesn't exist."""

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        model = from_state.apps.get_model(app_label, self.model_name)
        if column_exists(model._meta.db_table, self.name):
            super().database_forwards(app_label, schema_editor, from_state, to_state)


class ConditionalAddConstraint(migrations.AddConstraint):
    """AddConstraint that skips if constraint already exists."""

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        model = to_state.apps.get_model(app_label, self.model_name)
        with connection.cursor() as cursor:
            cursor.execute(
                """
                SELECT COUNT(*) FROM pg_constraint
                WHERE conrelid = %s::regclass AND conname = %s
                """,
                [model._meta.db_table, self.constraint.name],
            )
            row = cursor.fetchone()
            if row and row[0] > 0:
                return  # Constraint already exists
        super().database_forwards(app_label, schema_editor, from_state, to_state)


class ConditionalAddIndex(migrations.AddIndex):
    """AddIndex that skips if index already exists."""

    def database_forwards(self, app_label, schema_editor, from_state, to_state):
        with connection.cursor() as cursor:
            cursor.execute(
                """
                SELECT COUNT(*) FROM pg_indexes
                WHERE indexname = %s
                """,
                [self.index.name],
            )
            row = cursor.fetchone()
            if row and row[0] > 0:
                return  # Index already exists
        super().database_forwards(app_label, schema_editor, from_state, to_state)


class Migration(migrations.Migration):
    dependencies = [
        ("proteins", "0059_add_fluorophore_and_new_models"),
    ]

    operations = [
        # Step 1: Add new fields (nullable initially for migration)
        ConditionalAddField(
            model_name="spectrum",
            name="min_wave",
            field=models.SmallIntegerField(
                blank=True,
                null=True,
                help_text="Minimum wavelength in nm (inclusive)",
            ),
        ),
        ConditionalAddField(
            model_name="spectrum",
            name="max_wave",
            field=models.SmallIntegerField(
                blank=True,
                null=True,
                help_text="Maximum wavelength in nm (inclusive)",
            ),
        ),
        ConditionalAddField(
            model_name="spectrum",
            name="y_values",
            field=models.BinaryField(
                blank=True,
                null=True,
                help_text="Y values as float32 binary array, one value per nm from min to max wave",
            ),
        ),
        ConditionalAddField(
            model_name="spectrum",
            name="scale_factor",
            field=models.FloatField(
                blank=True,
                null=True,
                help_text=(
                    "Physical scaling constant. Meaning depends on subtype: "
                    "EX/ABS=extinction coeff (M^-1 cm^-1), EM=quantum yield, "
                    "2P=peak cross-section (GM), filters/cameras=1.0"
                ),
            ),
        ),
        ConditionalAddField(
            model_name="spectrum",
            name="peak_wave",
            field=models.SmallIntegerField(
                blank=True,
                null=True,
                help_text="Wavelength of peak intensity in nm",
            ),
        ),
        # Step 2: Migrate data from old format to new format
        migrations.RunPython(migrate_spectrum_data, migrations.RunPython.noop),
        # Step 3: Make min_wave, max_wave, y_values required
        migrations.AlterField(
            model_name="spectrum",
            name="min_wave",
            field=models.SmallIntegerField(
                help_text="Minimum wavelength in nm (inclusive)",
            ),
        ),
        migrations.AlterField(
            model_name="spectrum",
            name="max_wave",
            field=models.SmallIntegerField(
                help_text="Maximum wavelength in nm (inclusive)",
            ),
        ),
        migrations.AlterField(
            model_name="spectrum",
            name="y_values",
            field=models.BinaryField(
                help_text="Y values as float32 binary array, one value per nm from min to max wave",
            ),
        ),
        # Step 4: Remove the legacy data field
        ConditionalRemoveField(
            model_name="spectrum",
            name="data",
        ),
        # Step 5: Add CHECK constraint for single-owner validation
        ConditionalAddConstraint(
            model_name="spectrum",
            constraint=models.CheckConstraint(
                name="spectrum_single_owner",
                condition=(
                    models.Q(owner_fluor__isnull=False, owner_filter__isnull=True, owner_light__isnull=True, owner_camera__isnull=True)
                    | models.Q(owner_fluor__isnull=True, owner_filter__isnull=False, owner_light__isnull=True, owner_camera__isnull=True)
                    | models.Q(owner_fluor__isnull=True, owner_filter__isnull=True, owner_light__isnull=False, owner_camera__isnull=True)
                    | models.Q(owner_fluor__isnull=True, owner_filter__isnull=True, owner_light__isnull=True, owner_camera__isnull=False)
                ),
            ),
        ),
        # Step 6: Add covering index for metadata-only queries
        ConditionalAddIndex(
            model_name="spectrum",
            index=models.Index(
                fields=["status", "category", "subtype"],
                name="spectrum_metadata_idx",
            ),
        ),
        # Step 7: Add partial index for approved fluorophore spectra
        ConditionalAddIndex(
            model_name="spectrum",
            index=models.Index(
                fields=["owner_fluor_id"],
                name="spectrum_approved_fluor_idx",
                condition=models.Q(status="approved", owner_fluor_id__isnull=False),
            ),
        ),
    ]
