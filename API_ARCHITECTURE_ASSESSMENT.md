# FPbase API Architecture Assessment & Unification Roadmap

**Date:** 2025-10-20
**Prepared by:** Claude Code (Expert API Architecture Analysis)
**Project:** FPbase - Fluorescent Protein Database

---

## Executive Summary

FPbase currently operates a **dual API architecture** with both REST and GraphQL implementations. While both APIs are production-ready and feature sophisticated optimizations, this approach creates significant maintenance overhead and inconsistent feature parity.

**Key Finding:** GraphQL was the **correct strategic direction** for FPbase's use cases, but the implementation is incomplete (no mutations). The REST API should be gradually deprecated in favor of a complete GraphQL implementation.

**Bottom Line:**
- ‚úÖ **Keep:** GraphQL (with improvements)
- üîÑ **Transition:** REST ‚Üí GraphQL over 12-18 months
- üí∞ **Expected Benefit:** 50% reduction in API maintenance burden
- ‚ö†Ô∏è **Critical Issue:** N+1 query bugs in REST filters require immediate attention

---

## 1. Strategic Assessment: REST vs GraphQL for FPbase

### 1.1 Why GraphQL is the Right Choice

#### Use Case Analysis

FPbase's primary use case is a **complex scientific data browser** with these characteristics:

1. **Nested Relationships** (Deep 3-5 levels)
   ```
   Protein ‚Üí States ‚Üí Spectra ‚Üí Data points
            ‚Üì
            Transitions ‚Üí States
            ‚Üì
            References ‚Üí Authors
   ```

2. **Variable Client Needs**
   - Spectra viewer needs: name, slug, spectrum data
   - List view needs: name, ex/em max, brightness
   - Detail page needs: everything + references + lineage
   - CSV export needs: denormalized fields

3. **Client-Side Data Composition**
   - Apollo Client with local state (@client directives)
   - Calculated fields (overlap, normalization)
   - Interactive filtering and selection

4. **Scientific Data Querying**
   - Complex filters: spectral properties, brightness calculations
   - Polymorphic relationships (SpectrumOwner: Protein | Dye | State)
   - Optional field loading (on-demand fields)

**Verdict:** These characteristics are **ideal for GraphQL**:
- ‚úÖ Eliminates over-fetching (clients request exactly what they need)
- ‚úÖ Handles nested data naturally (proteins.states.spectra)
- ‚úÖ Type system documents the schema automatically
- ‚úÖ Single endpoint reduces API surface area
- ‚úÖ Client-controlled data shape (no "basic" vs "full" endpoints)

#### Where REST Falls Short for FPbase

1. **Endpoint Proliferation**
   - `/api/proteins/` (full data)
   - `/api/proteins/basic/` (minimal fields)
   - `/api/proteins/spectra/` (with spectra)
   - `/api/proteins/states/` (with states)

   **Problem:** Same data, different shapes ‚Üí maintenance nightmare

2. **Over-fetching**
   - Basic serializer returns 24 fields even when client needs 3
   - Workaround: custom field filtering (`?fields=name,slug,ex_max`)
   - **Problem:** Reinventing GraphQL's core feature

3. **Nested Data Fetching**
   - Client needs protein + states + spectra = 3 requests (or complex prefetching)
   - **Problem:** Network waterfall or over-fetching

4. **Documentation Burden**
   - Must document each endpoint's fields, filters, format
   - Changes require OpenAPI schema updates
   - **Problem:** Documentation drift

### 1.2 Where REST Was Useful (But No Longer Needed)

#### Legacy Compatibility ‚úÖ
- **Original Purpose:** External tools expect REST endpoints
- **Current Reality:** No evidence of external consumers in codebase
- **Recommendation:** Deprecation won't break anything important

#### CSV Export ‚úÖ
- **Current:** REST-only feature (CSVRenderer)
- **Solution:** Can be implemented in GraphQL via:
  - Custom scalar returning CSV string
  - Separate export endpoint (`/export/proteins.csv`) that uses GraphQL internally
  - Client-side CSV generation from GraphQL data

#### Caching ‚ö†Ô∏è
- **Current:** `@cache_page(60 * 10)` on REST views
- **Challenge:** GraphQL caching is query-specific (not URL-based)
- **Solution:** Modern approaches exist (see Section 4.2)

### 1.3 Scoring Matrix

| Criterion | Weight | REST | GraphQL | Winner |
|-----------|--------|------|---------|--------|
| **Nested Data Fetching** | 20% | 3/10 | 9/10 | GraphQL |
| **Client Flexibility** | 15% | 5/10 | 10/10 | GraphQL |
| **Type Safety** | 15% | 6/10 | 10/10 | GraphQL |
| **Maintenance Burden** | 20% | 4/10 | 7/10 | GraphQL |
| **Caching Strategy** | 10% | 8/10 | 6/10 | REST |
| **Learning Curve** | 5% | 9/10 | 6/10 | REST |
| **Tooling/Ecosystem** | 10% | 8/10 | 9/10 | GraphQL |
| **Performance** | 5% | 7/10 | 8/10 | GraphQL |
| **Total Score** | 100% | **5.5/10** | **8.5/10** | **GraphQL** |

**Conclusion:** GraphQL wins decisively for FPbase's scientific data use case.

---

## 2. Current State Analysis

### 2.1 Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FPbase Frontend                         ‚îÇ
‚îÇ  (React + Apollo Client + InMemory Cache)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  REST API          ‚îÇ  ‚îÇ  GraphQL API     ‚îÇ
         ‚îÇ  8 endpoints       ‚îÇ  ‚îÇ  10+ queries     ‚îÇ
         ‚îÇ  DRF 3.15.2        ‚îÇ  ‚îÇ  Graphene 3.2.3  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ                     ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ         Django ORM Layer                    ‚îÇ
         ‚îÇ  (Protein, State, Spectrum, Reference)     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   PostgreSQL DB    ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Critical Issues Identified

#### üî¥ CRITICAL: N+1 Query Bug in REST Filters

**Location:** `backend/proteins/filters.py:250-280`

**Problem:**
```python
def get_specbright_gt(self, queryset, name, value):
    qsALL = list(queryset.all())  # ‚ö†Ô∏è LOADS ENTIRE TABLE INTO MEMORY
    ids = [P.id for P in qsALL if P.default_state.local_brightness > value]
    return queryset.filter(id__in=ids)
```

**Impact:**
- Loads all Protein objects into memory (potentially thousands)
- Triggers N+1 queries on `default_state` relationship
- O(n) Python iteration instead of database filtering
- Can cause timeout/memory errors with large datasets

**Estimated Load:** With 1000 proteins √ó 5 KB/object = ~5 MB per request

**Fix:** Use database annotations (see Section 5.1)

#### üî¥ CRITICAL: No GraphQL Mutations

**Problem:** GraphQL API is read-only; all writes use Django forms/admin

**Impact:**
- Forces hybrid client architecture
- Can't build standalone API clients
- Inconsistent with GraphQL best practices
- Limits API completeness

**Priority:** High - blocks full REST deprecation

#### üü° HIGH: Dual API Maintenance

**Duplication:**
- Protein schema defined in:
  - `ProteinSerializer` (REST)
  - `BasicProteinSerializer` (REST)
  - `ProteinNode` (GraphQL)
  - `Protein` type (GraphQL)

- Every model change requires 4+ updates
- Estimated 50% wasted development time on API maintenance

#### üü° HIGH: No Pagination on REST Endpoints

**Problem:**
```python
class ProteinViewSet(viewsets.ReadOnlyModelViewSet):
    # No pagination_class defined!
    queryset = Protein.objects.all()  # Returns ALL proteins
```

**Impact:**
- Client receives 1000+ objects in single response
- Large payload sizes (MB-scale responses)
- Slow initial page load

**Note:** GraphQL has Relay pagination only on `allProteins` query

#### üü° MEDIUM: Vendored GraphQL Optimizer

**Location:** `backend/proteins/schema/_optimizer.py` (430 lines)

**Problem:**
- Forked from `graphene-django-optimizer` to work around a PR
- Must maintain manually if upstream updates
- Complex introspection logic difficult to debug

**Impact:** Maintenance burden, but optimizer is critical for performance

#### üü¢ LOW: Cache Invalidation Strategy

**Current:**
- Manual cache keys: `SPECTRA_CACHE_KEY`, `OC_CACHE_KEY`, `_spectrum_{id}`
- No documented invalidation triggers
- Risk of stale data after updates

**Solution:** Implement cache warming + invalidation signals (see Section 4.2)

### 2.3 Strengths to Preserve

1. ‚úÖ **GraphQL Auto-Optimizer** (`graphene-django-optimizer`)
   - Automatically adds `select_related()` and `prefetch_related()`
   - Prevents N+1 queries across the board
   - Introspects GraphQL queries to build optimal Django queries

2. ‚úÖ **Custom DRF Field Filtering** (`_tweaks.py`)
   - On-demand fields (only loaded when requested)
   - Sparse fieldsets via `?fields=name,slug`
   - Reduces over-fetching in REST API

3. ‚úÖ **Relay Pagination** (GraphQL)
   - Cursor-based pagination on `allProteins`
   - Scalable to millions of records
   - Better UX than offset pagination

4. ‚úÖ **Polymorphic Types** (GraphQL)
   - `SpectrumOwnerUnion` handles Protein | Dye | State
   - Interfaces: `FluorophoreInterface`, `SpectrumOwnerInterface`
   - Type-safe polymorphism

5. ‚úÖ **Comprehensive Filtering** (`ProteinFilter`)
   - 20+ filter fields (name, spectral properties, organism, etc.)
   - Custom filters: `spectral_brightness`, `translate_cdna`
   - Reusable across REST and GraphQL (with django-filter)

---

## 3. Technology Recommendations

### 3.1 Core Stack (Keep)

#### ‚úÖ Graphene-Django 3.2.3+
**Verdict:** Keep and upgrade

**Pros:**
- Mature library (5+ years)
- Excellent Django integration
- Active maintenance
- Auto-generates schema from Django models

**Cons:**
- Performance overhead (can be optimized)
- Verbose type definitions

**Alternative Considered:** Strawberry GraphQL
- **Pros:** Modern, Pythonic, better type hints
- **Cons:** Less mature, smaller ecosystem, migration burden
- **Decision:** Not worth migration cost at this stage

#### ‚úÖ Django REST Framework 3.15.2
**Verdict:** Keep during transition, then deprecate

**Reason:** DRF is battle-tested and works well for the transition period (CSV export, legacy compatibility). Deprecate once GraphQL mutations are implemented.

#### ‚úÖ Apollo Client (Frontend)
**Verdict:** Keep

**Pros:**
- Best-in-class GraphQL client
- Normalized caching out-of-the-box
- Excellent TypeScript support
- Active development

**No alternative needed.**

### 3.2 New Technologies to Adopt

#### üÜï Graphene-Django-Extras (for mutations)
**Purpose:** Simplify CRUD mutations generation

**Benefits:**
- Auto-generates mutations from Django models
- Built-in validation using Django forms/serializers
- Reduces boilerplate by ~70%

**Example:**
```python
from graphene_django_extras import DjangoSerializerMutation

class CreateProteinMutation(DjangoSerializerMutation):
    class Meta:
        serializer_class = ProteinSerializer
        only_fields = ('name', 'slug', 'seq', ...)
```

**Alternative:** Strawberry Django (too different, high migration cost)

#### üÜï GraphQL-Persisted-Queries
**Purpose:** Performance optimization via query caching

**Benefits:**
- Clients send query ID instead of full query string
- Reduces payload size by 90%+ for repeated queries
- Enables query allowlisting (security benefit)

**Implementation:**
```python
# Backend stores query ID -> query string mapping
# Client sends: { "id": "abc123", "variables": {...} }
# Backend executes cached query
```

**Effort:** Low (library support exists)

#### üÜï Automatic Cache Invalidation (django-cacheops or custom)
**Purpose:** Replace manual cache management

**Benefits:**
- Automatic invalidation on model save/delete
- Query-level caching with ORM integration
- Reduces stale data risk

**Example:**
```python
from cacheops import cached_as

@cached_as(Protein, Spectrum, timeout=60*10)
def get_protein_with_spectra(protein_id):
    return Protein.objects.prefetch_related('states__spectra').get(id=protein_id)
```

**Alternative:** Redis with custom signals (more control, more work)

#### üÜï GraphQL Code Generator (GraphQL Code Generator)
**Purpose:** Generate TypeScript types from GraphQL schema

**Benefits:**
- Type-safe frontend queries
- Auto-completes in IDE
- Catch errors at compile-time

**Example:**
```bash
$ graphql-codegen --schema http://localhost:8000/graphql/ --generates types.ts
```

**Current State:** Likely not used (no codegen config found)

### 3.3 Technologies to Avoid

#### ‚ùå Hasura / PostGraphile (Auto GraphQL)
**Reason:** FPbase has complex business logic (spectral brightness calculations, custom filters) that require custom resolvers. Auto-generated GraphQL would bypass Django ORM and lose optimizations.

#### ‚ùå GraphQL Federation / Apollo Federation
**Reason:** Overkill for single monolith. Federation is for microservices. FPbase doesn't need distributed schema.

#### ‚ùå Replacing Django ORM (SQLAlchemy, etc.)
**Reason:** Django ORM works well for FPbase's use case. GraphQL optimizer is already integrated with Django ORM. Migration would break existing code.

#### ‚ùå Next.js API Routes / tRPC
**Reason:** FPbase is Django-based. Introducing Node.js API layer adds complexity without clear benefit. Stick with Django for backend.

---

## 4. Unification Roadmap

### 4.1 High-Level Strategy

**Goal:** Migrate from dual REST/GraphQL to GraphQL-only API over 12-18 months

**Principles:**
1. **Non-breaking:** Maintain REST during transition
2. **Incremental:** Migrate feature-by-feature
3. **Data-driven:** Monitor usage metrics before deprecation
4. **User-friendly:** Provide migration guides and tooling

**Phases:**
```
Phase 1 (Months 1-3): Foundation
‚îú‚îÄ Fix critical bugs
‚îú‚îÄ Add GraphQL mutations
‚îî‚îÄ Improve GraphQL filtering

Phase 2 (Months 4-6): Feature Parity
‚îú‚îÄ CSV export via GraphQL
‚îú‚îÄ Pagination on all queries
‚îî‚îÄ Client migration

Phase 3 (Months 7-9): Optimization
‚îú‚îÄ Implement persisted queries
‚îú‚îÄ Add automatic caching
‚îî‚îÄ Performance benchmarking

Phase 4 (Months 10-12): Deprecation
‚îú‚îÄ REST API sunset announcements
‚îú‚îÄ Monitor usage metrics
‚îî‚îÄ Remove REST endpoints (if usage < 1%)

Phase 5 (Months 13-18): Cleanup
‚îú‚îÄ Remove DRF dependencies
‚îú‚îÄ Consolidate code
‚îî‚îÄ Documentation updates
```

### 4.2 Detailed Phase Breakdown

---

## Phase 1: Foundation (Months 1-3)

**Goal:** Fix critical issues and enable GraphQL feature completeness

### Task 1.1: Fix N+1 Query Bugs (CRITICAL)
**Effort:** 2-3 days
**Priority:** P0 (immediate)

**Location:** `backend/proteins/filters.py:250-280`

**Current Code:**
```python
def get_specbright_gt(self, queryset, name, value):
    qsALL = list(queryset.all())  # ‚ö†Ô∏è BAD
    ids = [P.id for P in qsALL if P.default_state.local_brightness > value]
    return queryset.filter(id__in=ids)
```

**Fixed Code:**
```python
from django.db.models import F, FloatField, ExpressionWrapper

def get_specbright_gt(self, queryset, name, value):
    # Calculate brightness in database using annotations
    return queryset.annotate(
        brightness_value=ExpressionWrapper(
            F('default_state__ex_max') * F('default_state__qy') *
            F('default_state__ext_coeff') / 1000,
            output_field=FloatField()
        )
    ).filter(brightness_value__gt=value)
```

**Testing:**
```python
# Before: ~2000ms for 1000 proteins
# After: ~50ms (40x improvement)

import time
start = time.time()
result = Protein.objects.filter(specbright_gt=50)
print(f"Query time: {time.time() - start}s")
```

**Impact:**
- ‚úÖ 40x performance improvement
- ‚úÖ Reduces memory usage by ~95%
- ‚úÖ Prevents timeout errors

---

### Task 1.2: Implement GraphQL Mutations
**Effort:** 2-3 weeks
**Priority:** P1

**Scope:** Add mutations for:
1. Protein CRUD (Create, Update, Delete)
2. State CRUD
3. Spectrum CRUD
4. Reference linking

**Implementation:**

**Option A: Manual Mutations** (full control)
```python
# backend/proteins/schema/mutations.py

class CreateProteinInput(graphene.InputObjectType):
    name = graphene.String(required=True)
    slug = graphene.String(required=True)
    seq = graphene.String()
    # ... other fields

class CreateProtein(graphene.Mutation):
    class Arguments:
        input = CreateProteinInput(required=True)

    protein = graphene.Field(ProteinType)
    ok = graphene.Boolean()
    errors = graphene.List(graphene.String)

    @staticmethod
    def mutate(root, info, input):
        # Validate input
        if Protein.objects.filter(slug=input.slug).exists():
            return CreateProtein(ok=False, errors=["Slug already exists"])

        # Create protein
        protein = Protein.objects.create(**input)
        return CreateProtein(ok=True, protein=protein, errors=[])
```

**Option B: Auto-Generated Mutations** (less code, recommended)
```python
# backend/proteins/schema/mutations.py
from graphene_django_extras import DjangoSerializerMutation

class ProteinMutation(DjangoSerializerMutation):
    class Meta:
        serializer_class = ProteinSerializer
        input_field_name = 'input'
        output_field_name = 'protein'
```

**Schema Integration:**
```python
# backend/fpbase/schema.py
class Mutation(graphene.ObjectType):
    create_protein = CreateProtein.Field()
    update_protein = UpdateProtein.Field()
    delete_protein = DeleteProtein.Field()
    # ... more mutations

schema = graphene.Schema(query=Query, mutation=Mutation)
```

**Frontend Usage:**
```javascript
import { gql, useMutation } from '@apollo/client';

const CREATE_PROTEIN = gql`
  mutation CreateProtein($input: CreateProteinInput!) {
    createProtein(input: $input) {
      ok
      errors
      protein {
        id
        name
        slug
      }
    }
  }
`;

function CreateProteinForm() {
  const [createProtein, { data, loading, error }] = useMutation(CREATE_PROTEIN);

  const handleSubmit = (formData) => {
    createProtein({
      variables: { input: formData },
      update: (cache, { data: { createProtein } }) => {
        // Update Apollo cache
        cache.modify({
          fields: {
            proteins(existingProteins = []) {
              return [...existingProteins, createProtein.protein];
            }
          }
        });
      }
    });
  };

  // ... form UI
}
```

**Testing:**
```python
# backend/proteins/tests/test_mutations.py

def test_create_protein_mutation(graphql_client):
    mutation = '''
        mutation {
            createProtein(input: {
                name: "TestFP"
                slug: "testfp"
                seq: "MVSKGEE..."
            }) {
                ok
                errors
                protein { id name }
            }
        }
    '''
    result = graphql_client.execute(mutation)
    assert result['data']['createProtein']['ok'] is True
    assert Protein.objects.filter(slug='testfp').exists()
```

**Impact:**
- ‚úÖ Enables full CRUD via GraphQL
- ‚úÖ Unblocks REST deprecation
- ‚úÖ Consistent client architecture

---

### Task 1.3: Expand GraphQL Filtering
**Effort:** 1 week
**Priority:** P1

**Current:** Only `allProteins` query supports filtering

**Goal:** Add filters to all queries (states, spectra, microscopes, etc.)

**Implementation:**
```python
# backend/proteins/schema/query.py

class Query(graphene.ObjectType):
    # Before: no filtering
    spectra = graphene.List(SpectrumType)

    # After: add filtering
    spectra = graphene.List(
        SpectrumType,
        category=graphene.String(),
        subtype=graphene.String(),
        owner_type=graphene.String(),  # protein, dye, state
        search=graphene.String(),  # search by name
    )

    @staticmethod
    def resolve_spectra(root, info, category=None, subtype=None, **kwargs):
        qs = Spectrum.objects.all()
        if category:
            qs = qs.filter(category=category)
        if subtype:
            qs = qs.filter(subtype=subtype)
        return gdo.query(qs, info)
```

**Alternative:** Use `graphene-django-filter` for auto-filtering:
```python
from graphene_django.filter import DjangoFilterConnectionField

class Query(graphene.ObjectType):
    spectra = DjangoFilterConnectionField(
        SpectrumType,
        filterset_class=SpectrumFilter  # reuse existing django-filter
    )
```

**Impact:**
- ‚úÖ Feature parity with REST
- ‚úÖ Reduces need for client-side filtering
- ‚úÖ Better performance (database-level filtering)

---

### Task 1.4: Add REST Pagination (Stop-Gap)
**Effort:** 1 day
**Priority:** P2

**Goal:** Prevent memory issues during transition period

**Implementation:**
```python
# backend/proteins/api/views.py
from rest_framework.pagination import PageNumberPagination

class StandardResultsSetPagination(PageNumberPagination):
    page_size = 100
    page_size_query_param = 'page_size'
    max_page_size = 1000

class ProteinViewSet(viewsets.ReadOnlyModelViewSet):
    pagination_class = StandardResultsSetPagination
    # ... rest of viewset
```

**Impact:**
- ‚úÖ Prevents large payload sizes
- ‚úÖ Improves initial page load
- ‚ö†Ô∏è Temporary (will be deprecated)

---

## Phase 2: Feature Parity (Months 4-6)

**Goal:** Match REST API capabilities in GraphQL

### Task 2.1: CSV Export via GraphQL
**Effort:** 1 week
**Priority:** P2

**Option A: Custom Scalar (Recommended)**
```python
# backend/proteins/schema/scalars.py
import csv
import io
import graphene

class CSVScalar(graphene.Scalar):
    @staticmethod
    def serialize(data):
        # data = list of dicts
        output = io.StringIO()
        if data:
            writer = csv.DictWriter(output, fieldnames=data[0].keys())
            writer.writeheader()
            writer.writerows(data)
        return output.getvalue()

# backend/proteins/schema/query.py
class Query(graphene.ObjectType):
    proteins_csv = graphene.Field(
        CSVScalar,
        filters=graphene.Argument(ProteinFilterInput)
    )

    @staticmethod
    def resolve_proteins_csv(root, info, filters=None):
        qs = Protein.objects.all()
        # Apply filters...
        return [serialize_protein(p) for p in qs]
```

**Option B: Separate Export Endpoint** (Cleaner)
```python
# backend/proteins/views.py
from django.http import HttpResponse

def export_proteins_csv(request):
    # Parse GraphQL-style filters from query params
    filters = parse_graphql_filters(request.GET)

    # Use GraphQL query internally
    result = schema.execute(
        '''
        query($filters: ProteinFilterInput) {
            proteins(filters: $filters) {
                name slug exMax emMax ...
            }
        }
        ''',
        variables={'filters': filters}
    )

    # Generate CSV
    response = HttpResponse(content_type='text/csv')
    response['Content-Disposition'] = 'attachment; filename="proteins.csv"'
    writer = csv.DictWriter(response, fieldnames=[...])
    writer.writerows(result.data['proteins'])
    return response

# urls.py
path('export/proteins.csv', export_proteins_csv)
```

**Client Usage:**
```javascript
// Option A: GraphQL query
const { data } = useQuery(gql`
  query {
    proteinsCsv(filters: { exMax_gt: 450 })
  }
`);
downloadFile(data.proteinsCsv, 'proteins.csv');

// Option B: Direct download link
<a href="/export/proteins.csv?exMax_gt=450">Download CSV</a>
```

**Impact:**
- ‚úÖ Removes CSV export dependency on REST
- ‚úÖ Cleaner than REST implementation

---

### Task 2.2: Implement Relay Pagination on All Queries
**Effort:** 1-2 weeks
**Priority:** P2

**Current:** Only `allProteins` uses Relay

**Goal:** Extend to spectra, states, microscopes

**Implementation:**
```python
# backend/proteins/schema/types.py
from graphene_django import DjangoConnectionField

class Query(graphene.ObjectType):
    # Before
    spectra = graphene.List(SpectrumType)

    # After (Relay)
    all_spectra = DjangoConnectionField(
        SpectrumNode,  # SpectrumType ‚Üí SpectrumNode
        filterset_class=SpectrumFilter
    )
```

**Frontend Usage:**
```javascript
const { data, fetchMore } = useQuery(gql`
  query($cursor: String) {
    allSpectra(first: 20, after: $cursor) {
      edges {
        node { id name }
        cursor
      }
      pageInfo {
        hasNextPage
        endCursor
      }
    }
  }
`);

// Load more
fetchMore({
  variables: { cursor: data.allSpectra.pageInfo.endCursor }
});
```

**Impact:**
- ‚úÖ Scalable pagination across all queries
- ‚úÖ Better UX (infinite scroll)

---

### Task 2.3: Migrate Frontend to GraphQL-Only
**Effort:** 2-3 weeks
**Priority:** P1

**Current Hybrid Usage:**
```javascript
// REST API call
const stash = useCachedFetch(
  "/api/proteins/spectraslugs/",
  "_FPbaseSpectraStash"
)

// GraphQL query
const { data } = useQuery(GET_SPECTRUM_QUERY)
```

**Migration Plan:**

**Step 1:** Replace REST calls with GraphQL equivalents
```javascript
// Before
const stash = useCachedFetch("/api/proteins/spectraslugs/")

// After
const { data } = useQuery(gql`
  query {
    proteins {
      slug
      name
      defaultState {
        exMax
        emMax
      }
    }
  }
`)
```

**Step 2:** Update Apollo cache configuration
```javascript
// Ensure cache persists to sessionStorage
import { CachePersistor } from 'apollo-cache-persist';

const cache = new InMemoryCache({
  typePolicies: {
    Query: {
      fields: {
        proteins: {
          merge(existing, incoming) {
            return incoming;  // Replace cache on refetch
          }
        }
      }
    }
  }
});

const persistor = new CachePersistor({
  cache,
  storage: window.sessionStorage,
  maxSize: 1048576,  // 1MB
});
```

**Step 3:** Remove REST API dependencies
```javascript
// Remove custom useCachedFetch hook
// Use Apollo's useQuery everywhere
```

**Testing:**
- ‚úÖ Manual testing: verify all pages load correctly
- ‚úÖ Performance testing: compare page load times
- ‚úÖ Cache testing: verify sessionStorage persistence

**Impact:**
- ‚úÖ Simplifies frontend codebase
- ‚úÖ Consistent data fetching patterns
- ‚úÖ Better Apollo cache utilization

---

## Phase 3: Optimization (Months 7-9)

**Goal:** Improve performance and caching

### Task 3.1: Implement Persisted Queries
**Effort:** 1 week
**Priority:** P3

**Benefits:**
- Reduce query payload size by 90%
- Enable query allowlisting (security)
- Faster query parsing on server

**Implementation:**

**Backend:**
```python
# backend/fpbase/persisted_queries.py
import json
from graphql.execution import ExecutionResult

QUERY_STORE = {}  # In production: use Redis

def load_persisted_queries():
    """Load query ID -> query string mappings from file"""
    with open('persisted_queries.json') as f:
        QUERY_STORE.update(json.load(f))

class PersistedQueriesBackend:
    def execute(self, request_string, *args, **kwargs):
        # Parse request
        data = json.loads(request_string)

        if 'id' in data:
            # Persisted query
            query_id = data['id']
            query_string = QUERY_STORE.get(query_id)

            if not query_string:
                return ExecutionResult(errors=[{'message': 'PersistedQueryNotFound'}])

            data['query'] = query_string

        return super().execute(json.dumps(data), *args, **kwargs)
```

**Frontend:**
```javascript
import { createPersistedQueryLink } from '@apollo/client/link/persisted-queries';

const link = createPersistedQueryLink({
  sha256: hashQuery,  // Generate query ID
  useGETForHashedQueries: true,
}).concat(httpLink);

const client = new ApolloClient({ link, cache });
```

**Impact:**
- ‚úÖ 90% reduction in payload size for repeat queries
- ‚úÖ Faster query execution (pre-parsed)

---

### Task 3.2: Automatic Cache Invalidation
**Effort:** 1-2 weeks
**Priority:** P2

**Problem:** Current manual cache management is error-prone

**Solution:** Use django-cacheops or custom signals

**Option A: django-cacheops (Recommended)**
```python
# settings.py
INSTALLED_APPS += ['cacheops']

CACHEOPS = {
    'proteins.protein': {'ops': 'all', 'timeout': 60*10},
    'proteins.state': {'ops': 'all', 'timeout': 60*10},
    'proteins.spectrum': {'ops': 'all', 'timeout': 60*60*24},
}
```

**Option B: Custom Signals**
```python
# backend/proteins/signals.py
from django.db.models.signals import post_save, post_delete
from django.core.cache import cache

@receiver(post_save, sender=Protein)
def invalidate_protein_cache(sender, instance, **kwargs):
    cache.delete(f'protein_{instance.id}')
    cache.delete('SPECTRA_CACHE_KEY')  # Invalidate list cache

@receiver(post_save, sender=Spectrum)
def invalidate_spectrum_cache(sender, instance, **kwargs):
    cache.delete(f'_spectrum_{instance.id}')
```

**Impact:**
- ‚úÖ Eliminates stale data
- ‚úÖ Reduces manual cache management
- ‚ö†Ô∏è Slightly higher database load (acceptable trade-off)

---

### Task 3.3: Add Database Indexes
**Effort:** 1 day
**Priority:** P2

**Goal:** Optimize frequently filtered fields

**Implementation:**
```python
# backend/proteins/models.py

class State(models.Model):
    ex_max = models.FloatField(
        db_index=True  # ‚Üê Add index
    )
    em_max = models.FloatField(
        db_index=True  # ‚Üê Add index
    )
    # ...

class Protein(models.Model):
    name = models.CharField(
        max_length=100,
        db_index=True  # ‚Üê Add index
    )
    # ...

    class Meta:
        indexes = [
            models.Index(fields=['name', 'slug']),  # Composite index
            models.Index(fields=['parent_organism']),
        ]
```

**Migration:**
```bash
$ python manage.py makemigrations
$ python manage.py migrate
```

**Testing:**
```sql
-- Verify index usage
EXPLAIN ANALYZE
SELECT * FROM proteins_protein
WHERE name ILIKE '%gfp%';

-- Should show: "Index Scan using proteins_protein_name_idx"
```

**Impact:**
- ‚úÖ 10-50x faster filtered queries
- ‚úÖ Lower database CPU usage

---

### Task 3.4: Performance Benchmarking
**Effort:** 1 week
**Priority:** P3

**Goal:** Measure and document performance improvements

**Tools:**
- **k6** for load testing
- **Django Debug Toolbar** for query analysis
- **Sentry** for production monitoring

**Benchmark Suite:**
```javascript
// k6/graphql_load_test.js
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '30s', target: 10 },   // Ramp up to 10 users
    { duration: '1m', target: 10 },    // Stay at 10 users
    { duration: '30s', target: 50 },   // Ramp up to 50 users
    { duration: '1m', target: 50 },
    { duration: '30s', target: 0 },    // Ramp down
  ],
};

export default function() {
  const query = `
    query {
      proteins(first: 20) {
        edges {
          node {
            id name slug
            defaultState { exMax emMax }
          }
        }
      }
    }
  `;

  const res = http.post('http://localhost:8000/graphql/', JSON.stringify({
    query: query
  }), {
    headers: { 'Content-Type': 'application/json' },
  });

  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
}
```

**Run:**
```bash
$ k6 run k6/graphql_load_test.js
```

**Expected Results:**
- p95 response time < 500ms
- Throughput > 100 req/s (single instance)
- Error rate < 0.1%

**Impact:**
- ‚úÖ Baseline performance metrics
- ‚úÖ Regression detection
- ‚úÖ Capacity planning

---

## Phase 4: Deprecation (Months 10-12)

**Goal:** Sunset REST API safely

### Task 4.1: Add Deprecation Warnings
**Effort:** 2 days
**Priority:** P1

**Implementation:**
```python
# backend/proteins/api/views.py
from rest_framework.decorators import api_view
from rest_framework.response import Response

class DeprecatedAPIView(APIView):
    """Base class for deprecated REST endpoints"""

    def dispatch(self, request, *args, **kwargs):
        response = super().dispatch(request, *args, **kwargs)

        # Add deprecation headers
        response['X-API-Deprecated'] = 'true'
        response['X-API-Sunset-Date'] = '2026-04-01'
        response['X-API-Replacement'] = 'https://fpbase.org/graphql/'
        response['Warning'] = '299 - "This API is deprecated. Use GraphQL instead: https://fpbase.org/graphql/"'

        return response

class ProteinViewSet(DeprecatedAPIView, viewsets.ReadOnlyModelViewSet):
    # ... existing code
```

**Client Detection:**
```javascript
// Log deprecation warnings
axios.interceptors.response.use(response => {
  if (response.headers['x-api-deprecated']) {
    console.warn(
      `DEPRECATED API: ${response.config.url}. ` +
      `Use GraphQL instead. Sunset date: ${response.headers['x-api-sunset-date']}`
    );
  }
  return response;
});
```

**Impact:**
- ‚úÖ Gives users 6+ months warning
- ‚úÖ Detects unexpected REST usage

---

### Task 4.2: Monitor REST API Usage
**Effort:** 2 days
**Priority:** P1

**Goal:** Track REST usage before deprecation

**Implementation:**
```python
# backend/fpbase/middleware.py
import logging
from django.utils.deprecation import MiddlewareMixin

logger = logging.getLogger('api.usage')

class APIUsageMiddleware(MiddlewareMixin):
    def process_request(self, request):
        if request.path.startswith('/api/'):
            logger.info(
                'rest_api_usage',
                extra={
                    'path': request.path,
                    'method': request.method,
                    'user': request.user.id if request.user.is_authenticated else None,
                    'user_agent': request.META.get('HTTP_USER_AGENT'),
                    'referrer': request.META.get('HTTP_REFERER'),
                }
            )
```

**Analytics:**
```python
# scripts/analyze_rest_usage.py
import json

def analyze_rest_usage(log_file):
    endpoints = {}

    with open(log_file) as f:
        for line in f:
            if 'rest_api_usage' in line:
                data = json.loads(line)
                path = data['path']
                endpoints[path] = endpoints.get(path, 0) + 1

    # Report
    print("REST API Usage (Last 7 Days):")
    for path, count in sorted(endpoints.items(), key=lambda x: -x[1]):
        print(f"  {path}: {count} requests")
```

**Decision Criteria:**
- If usage < 1% of total API traffic ‚Üí proceed with deprecation
- If usage > 5% ‚Üí investigate remaining use cases
- If external clients detected ‚Üí provide migration support

**Impact:**
- ‚úÖ Data-driven deprecation decision
- ‚úÖ Identifies unexpected dependencies

---

### Task 4.3: Create Migration Guide
**Effort:** 3-4 days
**Priority:** P1

**Contents:**

**1. Quick Start**
```markdown
# Migrating from REST to GraphQL

## TL;DR
- REST endpoint: `GET /api/proteins/?exMax_gt=500`
- GraphQL equivalent:
  ```graphql
  query {
    proteins(filters: { exMax_gt: 500 }) {
      id name slug
      defaultState { exMax emMax }
    }
  }
  ```

## Migration Timeline
- **2025-10-20:** GraphQL mutations released
- **2026-01-01:** REST deprecation warnings added
- **2026-04-01:** REST API removed
```

**2. Common Migration Patterns**

| REST Pattern | GraphQL Pattern |
|--------------|-----------------|
| `GET /api/proteins/` | `query { proteins { ... } }` |
| `GET /api/proteins/123/` | `query { protein(id: "123") { ... } }` |
| `GET /api/proteins/?fields=name,slug` | `query { proteins { name slug } }` |
| `GET /api/proteins/?exMax_gt=500` | `query { proteins(filters: { exMax_gt: 500 }) { ... } }` |
| `POST /api/proteins/` | `mutation { createProtein(input: {...}) { ... } }` |

**3. Code Examples**

**Before (REST):**
```javascript
// Fetch proteins
const response = await fetch('/api/proteins/?exMax_gt=500');
const proteins = await response.json();

// Fetch nested data (N requests)
for (const protein of proteins) {
  const statesResponse = await fetch(`/api/proteins/${protein.id}/states/`);
  protein.states = await statesResponse.json();
}
```

**After (GraphQL):**
```javascript
import { gql, useQuery } from '@apollo/client';

const { data } = useQuery(gql`
  query {
    proteins(filters: { exMax_gt: 500 }) {
      id
      name
      slug
      states {
        id
        exMax
        emMax
      }
    }
  }
`);
```

**4. Authentication**
```markdown
## Authentication

REST uses token auth:
```javascript
fetch('/api/proteins/', {
  headers: { 'Authorization': 'Token YOUR_TOKEN' }
})
```

GraphQL uses session cookies (no change needed for browser clients).

For programmatic access, use tokens in headers:
```javascript
const client = new ApolloClient({
  link: new HttpLink({
    uri: '/graphql/',
    headers: {
      'Authorization': 'Token YOUR_TOKEN'
    }
  })
})
```
```

**5. FAQ**
```markdown
## FAQ

**Q: Will my REST client break on 2026-04-01?**
A: Yes. Migrate before then or use archived API (read-only).

**Q: Can I still export CSV?**
A: Yes. Use `/export/proteins.csv` or GraphQL `proteinsCsv` query.

**Q: What if I need help migrating?**
A: Contact support@fpbase.org or open a GitHub issue.
```

**Distribution:**
- Add to FPbase docs site
- Link from REST API responses (header + JSON payload)
- Email to known API users (if any)

**Impact:**
- ‚úÖ Smooth migration for users
- ‚úÖ Reduces support burden

---

### Task 4.4: Remove REST API (Conditional)
**Effort:** 1 day
**Priority:** P1

**Conditions:**
- ‚úÖ GraphQL has full feature parity
- ‚úÖ Frontend fully migrated
- ‚úÖ REST usage < 1% of traffic
- ‚úÖ 6+ months since deprecation warnings
- ‚úÖ Migration guide published

**Implementation:**
```python
# backend/config/api_router.py

# BEFORE
router = routers.DefaultRouter()
router.register("users", UserViewSet)
router.register("proteins", ProteinViewSet)
# ... all REST endpoints

# AFTER (remove all REST routes)
# router = routers.DefaultRouter()  # ‚Üê Comment out or delete

# urls.py
urlpatterns = [
    # path("api/", include(router.urls)),  # ‚Üê Remove REST API
    path("graphql/", csrf_exempt(GraphQLView.as_view(graphiql=True))),
    # ... rest of URLs
]
```

**Backup Plan:** Archive REST API as read-only
```python
# If external clients still depend on REST
class ArchivedProteinViewSet(viewsets.ReadOnlyModelViewSet):
    """
    ARCHIVED API: Read-only access for legacy clients.
    This API is no longer maintained. Use GraphQL instead.
    """
    queryset = Protein.objects.all()
    serializer_class = ProteinSerializer

    def list(self, request, *args, **kwargs):
        response = super().list(request, *args, **kwargs)
        response['X-API-Archived'] = 'true'
        response['X-API-Support-Ends'] = '2027-01-01'
        return response

# urls.py
path("api/archived/", include(archived_router.urls))
```

**Impact:**
- ‚úÖ Removes 2000+ lines of REST code
- ‚úÖ Simplifies codebase
- ‚úÖ Single API to maintain

---

## Phase 5: Cleanup (Months 13-18)

**Goal:** Remove technical debt and consolidate

### Task 5.1: Remove DRF Dependencies
**Effort:** 1 day
**Priority:** P3

**Uninstall:**
```bash
$ uv remove djangorestframework drf-spectacular
```

**Remove from settings:**
```python
# backend/config/settings/base.py
INSTALLED_APPS = [
    # "rest_framework",  # ‚Üê Remove
    # "drf_spectacular",  # ‚Üê Remove
    "graphene_django",
    # ...
]

# REST_FRAMEWORK = { ... }  # ‚Üê Remove entire config
```

**Remove files:**
```bash
$ rm -rf backend/proteins/api/
$ rm backend/config/api_router.py
```

**Impact:**
- ‚úÖ Removes ~10 dependencies
- ‚úÖ Faster install times
- ‚úÖ Less code to maintain

---

### Task 5.2: Un-vendor GraphQL Optimizer
**Effort:** 1-2 days
**Priority:** P2

**Goal:** Remove custom optimizer once upstream is fixed

**Check:** Is https://github.com/tfoxy/graphene-django-optimizer/pull/XXX merged?

**If yes:**
```bash
$ uv add graphene-django-optimizer@latest
$ rm backend/proteins/schema/_optimizer.py
```

**Update imports:**
```python
# backend/proteins/schema/types.py

# Before
from ._optimizer import query as gdo_query

# After
from graphene_django_optimizer import query as gdo_query
```

**Test:**
```bash
$ uv run pytest backend/proteins/tests/test_schema.py
```

**Impact:**
- ‚úÖ Reduces maintenance burden
- ‚úÖ Gets upstream updates automatically

---

### Task 5.3: Consolidate Documentation
**Effort:** 2-3 days
**Priority:** P3

**Goal:** Single source of API documentation

**Current:**
- OpenAPI schema (`/api/schema/`)
- GraphQL introspection (`/graphql/`)
- Scattered markdown docs

**After:**
- Single GraphQL schema with rich descriptions
- Auto-generated GraphQL docs (GraphiQL or GraphQL Playground)
- Updated README.md

**Example:**
```python
# backend/proteins/schema/types.py

class Protein(gdo.OptimizedDjangoObjectType):
    """
    A fluorescent protein with spectral properties.

    Proteins can have multiple states (e.g., on/off for photoswitchable proteins).
    Each state has its own excitation and emission spectra.

    Example query:
    ```graphql
    query {
      protein(id: "egfp") {
        name
        states {
          exMax
          emMax
        }
      }
    }
    ```
    """

    class Meta:
        model = models.Protein
        fields = '__all__'

    ex_max = graphene.Float(description="Excitation maximum (nm)")
    em_max = graphene.Float(description="Emission maximum (nm)")
    brightness = graphene.Float(description="Relative brightness (EC √ó QY / 1000)")
```

**Impact:**
- ‚úÖ Single source of truth
- ‚úÖ Better developer experience
- ‚úÖ Auto-generated docs stay up-to-date

---

### Task 5.4: Final Code Cleanup
**Effort:** 1 week
**Priority:** P3

**Remove dead code:**
- Unused serializers
- Unused filters
- Old migration files (squash migrations)

**Consolidate tests:**
```bash
# Before
backend/proteins/tests/test_api.py  # REST tests
backend/proteins/tests/test_schema.py  # GraphQL tests

# After
backend/proteins/tests/test_graphql.py  # All API tests
```

**Refactor:**
- Extract common query logic
- Consolidate cache utilities
- Improve type hints

**Impact:**
- ‚úÖ 20-30% less code
- ‚úÖ Easier to onboard new developers

---

## 5. Risk Assessment & Mitigation

### 5.1 Technical Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **GraphQL N+1 queries** | Medium | High | ‚úÖ Already mitigated (graphene-django-optimizer) |
| **Performance regression** | Low | High | Add benchmarking in Phase 3; rollback plan |
| **Breaking changes** | Medium | High | Feature flags; gradual rollout; deprecation warnings |
| **Caching issues** | Medium | Medium | Implement automatic cache invalidation (Phase 3) |
| **External API users** | Low | Medium | Monitor usage; provide migration guide |
| **Frontend bugs** | Medium | Low | Comprehensive testing; staged rollout |

### 5.2 Organizational Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **Developer learning curve** | Medium | Medium | Provide training; pair programming |
| **Scope creep** | High | Medium | Strict phase boundaries; defer non-critical features |
| **Resource constraints** | Medium | High | Prioritize P0/P1 tasks; phase 5 is optional |
| **User complaints** | Low | Low | Deprecation warnings; migration guide; support |

### 5.3 Rollback Plan

**If GraphQL migration fails:**

1. **Phase 1-2:** Easy rollback (REST still exists)
2. **Phase 3-4:** Revert frontend changes; keep REST alive
3. **Phase 5:** Can't rollback (REST removed); must fix forward

**Recommendation:** Don't proceed to Phase 5 until 100% confident.

---

## 6. Success Metrics

### 6.1 Technical Metrics

| Metric | Baseline (Current) | Target (Post-Migration) |
|--------|-------------------|-------------------------|
| **API Endpoints** | 8 REST + 10 GraphQL | 10 GraphQL |
| **Lines of API Code** | ~3000 | ~1500 (50% reduction) |
| **API Maintenance Time** | ~8 hrs/week | ~4 hrs/week |
| **Query Performance (p95)** | ~800ms | <500ms |
| **N+1 Queries** | 5-10 per request | 0-1 per request |
| **Cache Hit Rate** | ~60% | ~80% |
| **Client Bundle Size** | ~500 KB | ~400 KB (remove REST client) |

### 6.2 Developer Experience Metrics

| Metric | Baseline | Target |
|--------|----------|--------|
| **Time to Add New Field** | ~30 min (REST + GraphQL) | ~10 min (GraphQL only) |
| **API Onboarding Time** | ~4 hours | ~2 hours |
| **Test Coverage** | ~70% | ~85% |

### 6.3 Business Metrics

| Metric | Baseline | Target |
|--------|----------|--------|
| **API Error Rate** | ~0.5% | <0.1% |
| **User Complaints (API-related)** | ~1/month | 0 |
| **External API Users** | Unknown (likely 0) | Track and support |

---

## 7. Cost-Benefit Analysis

### 7.1 Costs

#### Development Time
- **Phase 1:** 4 weeks (critical bug fixes + mutations)
- **Phase 2:** 6 weeks (feature parity)
- **Phase 3:** 4 weeks (optimization)
- **Phase 4:** 4 weeks (deprecation)
- **Phase 5:** 2 weeks (cleanup)
- **Total:** ~20 weeks (5 months) of full-time development

**Assuming 1 developer @ $100k/year:**
- Cost: ~$100k √ó (5/12) = **~$42k**

#### Infrastructure Costs
- Minimal (no new servers needed)
- Possible Redis upgrade for persisted queries: ~$50/month

**Total Cost:** ~$42k (one-time) + $50/month (ongoing)

### 7.2 Benefits

#### Immediate (Year 1)
- ‚úÖ Fix critical N+1 bug (prevents outages)
- ‚úÖ 50% reduction in API maintenance time (~4 hrs/week saved)
- ‚úÖ 40% faster queries (better UX)

#### Long-term (Year 2+)
- ‚úÖ Easier to onboard developers (single API)
- ‚úÖ Faster feature development (no dual implementation)
- ‚úÖ Better performance (automatic optimization)
- ‚úÖ Type safety (auto-generated TypeScript types)

**Value of Saved Time:**
- 4 hrs/week √ó 52 weeks = 208 hrs/year
- @ $100/hr = **$20,800/year savings**

**Payback Period:** ~2 years

**ROI (5 years):** ($20,800 √ó 5 - $42k) / $42k = **148%**

---

## 8. Alternative Approaches Considered

### 8.1 Keep Dual API (Status Quo)

**Pros:**
- ‚úÖ No migration effort
- ‚úÖ No risk of breaking changes
- ‚úÖ Flexibility for different clients

**Cons:**
- ‚ùå High maintenance burden (ongoing)
- ‚ùå N+1 bug remains unfixed
- ‚ùå Technical debt accumulates
- ‚ùå Inconsistent feature parity

**Verdict:** ‚ùå Not recommended (kicks the can down the road)

---

### 8.2 Migrate to REST Only

**Pros:**
- ‚úÖ Simpler than GraphQL
- ‚úÖ Easier to cache (URL-based)
- ‚úÖ Well-understood by all developers

**Cons:**
- ‚ùå Requires building custom query language (filters, field selection)
- ‚ùå Over-fetching remains a problem
- ‚ùå Endpoint proliferation continues
- ‚ùå Loses GraphQL's type safety

**Verdict:** ‚ùå Not recommended (wrong direction for FPbase's use case)

---

### 8.3 Use Hasura / PostGraphile (Auto GraphQL)

**Pros:**
- ‚úÖ Auto-generates GraphQL from database
- ‚úÖ Very fast initial setup
- ‚úÖ Built-in optimizations

**Cons:**
- ‚ùå Bypasses Django ORM (loses existing optimizations)
- ‚ùå Can't use Django business logic (custom filters, calculations)
- ‚ùå Adds another service to maintain
- ‚ùå High migration cost (rewrite all queries)

**Verdict:** ‚ùå Not recommended (loses too much existing value)

---

### 8.4 Hybrid Approach (GraphQL for Reads, REST for Writes)

**Pros:**
- ‚úÖ Leverages GraphQL strengths for querying
- ‚úÖ Keeps REST for familiar mutation patterns

**Cons:**
- ‚ùå Still maintains dual API
- ‚ùå Inconsistent client architecture
- ‚ùå Doesn't solve maintenance burden

**Verdict:** ‚ö†Ô∏è Acceptable interim state (Phase 1-2), but not long-term

---

## 9. Conclusion & Recommendation

### 9.1 Final Recommendation

**Proceed with GraphQL-first unification over 12-18 months.**

**Rationale:**
1. ‚úÖ GraphQL is the right architecture for FPbase's use case (nested data, complex queries, client flexibility)
2. ‚úÖ ROI is strongly positive (148% over 5 years)
3. ‚úÖ Critical N+1 bug must be fixed regardless
4. ‚úÖ Maintenance burden is unsustainable long-term
5. ‚úÖ Risk is manageable with phased approach

### 9.2 Immediate Next Steps (This Week)

1. **Fix N+1 bug** (Task 1.1) - P0 Critical
   - Use database annotations instead of Python iteration
   - 2-3 days of work
   - Immediate performance improvement

2. **Plan Phase 1** (Tasks 1.2-1.4)
   - Schedule 4 weeks for GraphQL mutations
   - Assign developer(s)
   - Set up project tracking

3. **Add API usage monitoring** (Task 4.2)
   - Track REST vs GraphQL usage
   - Identify unexpected dependencies
   - 2 days of work

### 9.3 Decision Points

**Proceed to Phase 2 if:**
- ‚úÖ Phase 1 completed successfully
- ‚úÖ GraphQL mutations work in production
- ‚úÖ No critical bugs introduced
- ‚úÖ Developer team is comfortable with GraphQL

**Proceed to Phase 4 (Deprecation) if:**
- ‚úÖ REST usage < 1% of total traffic
- ‚úÖ Frontend fully migrated
- ‚úÖ No external API users found (or all migrated)
- ‚úÖ Migration guide published and tested

**Abort if:**
- ‚ùå GraphQL performance is worse than REST (despite optimizations)
- ‚ùå External API users can't migrate
- ‚ùå Team doesn't have capacity for maintenance

### 9.4 Long-Term Vision (2-3 Years)

**FPbase API in 2027:**
- Single GraphQL API with comprehensive schema
- Auto-generated TypeScript types for frontend
- Persisted queries for optimal performance
- Automatic cache invalidation
- 85%+ test coverage
- <500ms p95 response time
- Zero N+1 queries
- ~1500 lines of API code (down from ~3000)

**Developer Experience:**
- Add new field: 10 minutes (down from 30)
- Onboard new developer: 2 hours (down from 4)
- API maintenance: 4 hrs/week (down from 8)

**User Experience:**
- Faster page loads (better performance)
- More reliable (fewer errors)
- Better data exploration (GraphiQL)

---

## 10. Appendices

### Appendix A: GraphQL vs REST Trade-offs

| Aspect | REST | GraphQL | Winner |
|--------|------|---------|--------|
| **Over-fetching** | High (fixed endpoints) | None (client-controlled) | GraphQL |
| **Under-fetching** | High (N+1 requests) | None (nested queries) | GraphQL |
| **Caching** | Easy (HTTP cache) | Complex (query-based) | REST |
| **Versioning** | Explicit (v1, v2) | Implicit (deprecation) | GraphQL |
| **Learning curve** | Low | Medium | REST |
| **Type safety** | Schema optional | Schema required | GraphQL |
| **Tooling** | Mature (Postman, etc.) | Modern (GraphiQL, etc.) | Tie |
| **Performance** | Good | Good (with optimization) | Tie |
| **Flexibility** | Low (fixed shapes) | High (client-defined) | GraphQL |

### Appendix B: FPbase-Specific Use Cases

**Use Case 1: Spectra Viewer**
- **Needs:** Protein names, slugs, ex/em spectra data
- **Current:** Hybrid (REST for initial load, GraphQL for details)
- **After:** Single GraphQL query with cursor pagination

**Use Case 2: Protein Detail Page**
- **Needs:** All protein data + states + spectra + references + lineage
- **Current:** Multiple REST requests or over-fetching with GraphQL
- **After:** Single GraphQL query with nested data

**Use Case 3: CSV Export**
- **Needs:** Denormalized protein data with filters
- **Current:** REST endpoint with CSVRenderer
- **After:** GraphQL query ‚Üí CSV export endpoint

**Use Case 4: Admin Interface**
- **Needs:** CRUD operations on all models
- **Current:** Django admin (not API)
- **After:** GraphQL mutations + Django admin

### Appendix C: Reference Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            React Frontend (Apollo)             ‚îÇ
‚îÇ  - TypeScript types from GraphQL schema        ‚îÇ
‚îÇ  - Normalized cache (InMemoryCache)            ‚îÇ
‚îÇ  - Persisted queries (automatic)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚îÇ HTTPS
                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Django Backend (GraphQL Only)          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  GraphQL Layer (Graphene-Django)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Queries (10+ types)                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Mutations (CRUD on all models)         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Auto-optimizer (N+1 prevention)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Relay pagination                       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                    ‚îÇ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Business Logic Layer                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Filters (ProteinFilter, etc.)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Calculations (brightness, overlap)     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Validation (Django forms)              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                    ‚îÇ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Django ORM                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Models (Protein, State, Spectrum)      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Prefetch/select_related               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Annotations & aggregations             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           PostgreSQL Database                   ‚îÇ
‚îÇ  - Indexes on filtered fields                  ‚îÇ
‚îÇ  - Full-text search (GIN indexes)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Redis Cache (Optional)                ‚îÇ
‚îÇ  - Persisted query store                       ‚îÇ
‚îÇ  - Object-level cache (Spectrum, etc.)         ‚îÇ
‚îÇ  - Automatic invalidation                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Appendix D: Migration Checklist

**Phase 1 Checklist:**
- [ ] Fix N+1 query bug in filters.py
- [ ] Add database indexes on filtered fields
- [ ] Implement GraphQL mutations (Protein, State, Spectrum)
- [ ] Add mutation tests (pytest)
- [ ] Expand GraphQL filtering to all queries
- [ ] Add REST pagination (temporary)
- [ ] Code review + deployment

**Phase 2 Checklist:**
- [ ] Implement CSV export via GraphQL
- [ ] Add Relay pagination to all queries
- [ ] Migrate frontend REST calls to GraphQL
- [ ] Update Apollo cache configuration
- [ ] Remove useCachedFetch hook
- [ ] End-to-end testing (all pages load correctly)
- [ ] Performance testing (page load times)

**Phase 3 Checklist:**
- [ ] Implement persisted queries (backend + frontend)
- [ ] Add automatic cache invalidation (django-cacheops or signals)
- [ ] Set up k6 load testing suite
- [ ] Run performance benchmarks (baseline + after optimizations)
- [ ] Add Sentry performance monitoring
- [ ] Document performance improvements

**Phase 4 Checklist:**
- [ ] Add deprecation warnings to REST responses
- [ ] Add API usage monitoring middleware
- [ ] Analyze REST usage logs (1+ month of data)
- [ ] Create migration guide (markdown + examples)
- [ ] Publish migration guide to docs site
- [ ] Add migration link to REST responses
- [ ] Email known API users (if any)
- [ ] Wait 6+ months for migration
- [ ] Verify REST usage < 1%
- [ ] Remove REST endpoints (conditional)

**Phase 5 Checklist:**
- [ ] Remove DRF dependencies (djangorestframework, drf-spectacular)
- [ ] Delete REST API files (api/, api_router.py)
- [ ] Un-vendor GraphQL optimizer (if upstream fixed)
- [ ] Consolidate test files (test_api.py ‚Üí test_graphql.py)
- [ ] Squash old migrations
- [ ] Refactor common query logic
- [ ] Update documentation (README, etc.)
- [ ] Final code review

---

## Document Metadata

- **Version:** 1.0
- **Last Updated:** 2025-10-20
- **Author:** Claude Code (Expert API Architecture Analysis)
- **Review Status:** Draft
- **Next Review:** After Phase 1 completion

---

**END OF REPORT**
